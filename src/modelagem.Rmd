---
title: "Modelagem"
author: "Davi Guerra"
date: ""
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, message = F)
```

```{r}
setwd('D:/pibic')
pacman::p_load('tidyverse','DescTools')

source('./src/utils/handle_data.R')
options(scipen=999)

#Retirando essas variáveis dos bancos de dados pois elas apresentavam muitos valores faltantes
#na hora das análises e os valores que restavam não influenciava muito na variável resposta

df_treino = read.csv('data/train.csv') %>%
  dplyr::select(!c(Alley,PoolQC,Fence,MiscFeature)) 

df_test = read.csv('data/test.csv') %>% 
  dplyr::select(!c(Alley,PoolQC,Fence,MiscFeature))

y = df_treino$SalePrice

df_treino = df_treino %>% 
  dplyr::select(!c(SalePrice))
```


### Separando as variáveis numéricas e categóricas
```{r}
col_num = sapply(df_treino, typeof) == "integer"
col_char = sapply(df_treino, typeof) == "character"

numericas = df_treino[col_num]
categoricas = df_treino[col_char]

length(numericas) + length(categoricas)
```

```{r}

pseudo_vars_numericas = c("BsmtHalfBath","BsmtFullBath","FullBath","HalfBath","BedroomAbvGr","KitchenAbvGr","Fireplaces")
 
numericas = numericas %>% 
   select(!pseudo_vars_numericas)
 
categoricas = cbind(categoricas, df_treino[pseudo_vars_numericas])
categoricas[pseudo_vars_numericas] = sapply(categoricas[pseudo_vars_numericas], as.factor)
 
```

```{r}
#library(corrplot)
numericas_tratado = na.omit(numericas[-1])
correlation_matrix = cor(numericas_tratado)

num_vars_correlated = part_variables_by_correlation(correlation_matrix, 0.5)$correlacionadas
num_vars_not_correlated = part_variables_by_correlation(correlation_matrix, 0.5)$nao_correlacionadas %>% unlist

num_names_ordered = sapply(num_vars_correlated, function(x) length(x)) %>% sort(decreasing = T) %>% names

enough_vars_correlated = find_list_enough_vars_correlated(num_vars_correlated[num_names_ordered])

print('Número de variáveis numéricas')
print(length(names(numericas)))

print('Número de variáveis que NÃO possuem uma correlação forte com alguma variável')
print(length(num_vars_correlated))

print('Número de variáveis que possuem uma correlação forte com alguma variável')
print(length(num_vars_not_correlated))

print('Número de variáveis que conseguem estar correlacionadas com todas as outras variáveis')
print(length(enough_vars_correlated))
```

```{r}
matrix_coef_contigency = calcule_multiple_coef_contigency(categoricas) 


cat_vars_associated = part_variables_by_correlation(matrix_coef_contigency, 0.5)$correlacionadas
cat_vars_not_associated = part_variables_by_correlation(matrix_coef_contigency, 0.5)$nao_correlacionadas %>% unlist

cat_names_ordered = sapply(cat_vars_associated, function(x) length(x)) %>% sort(decreasing = T) %>% names

enough_vars_associated = find_list_enough_vars_correlated(cat_vars_associated[cat_names_ordered])


print('Número de variáveis categóricas')
print(length(names(categoricas)))

print('Número de variáveis que NÃO possuem uma associação forte com alguma variável')
print(length(cat_vars_not_associated))

print('Número de variáveis que possuem uma associação forte com alguma variável')
print(length(names(cat_vars_associated)))

print('Número de variáveis que conseguem estar associada com todas as outras variáveis')
print(length(enough_vars_associated))
```

```{r}
vec_enough_vars_associated_or_correlated = c(enough_vars_associated,enough_vars_correlated)
vec_vars_not_associated_or_correlated = c(cat_vars_not_associated, num_vars_not_correlated)

vec_util_vars = c(vec_enough_vars_associated_or_correlated, vec_enough_vars_associated_or_correlated)
df_treino[vec_util_vars]
```


## Gráfico de Dispersão das covariáveis numéricas pela variável resposta
```{r}
cbind(numericas[1:12],y) %>% 
  pivot_longer(-y) %>% 
  ggplot(aes(x = value, y = y))+
    geom_point()+
    facet_wrap(~name, scales = 'free')

cbind(numericas[13:25],y) %>% 
  pivot_longer(-y) %>% 
  ggplot(aes(x = value, y = y))+
    geom_point()+
    facet_wrap(~name, scales = 'free')

cbind(numericas[26:37],y) %>% 
  pivot_longer(-y) %>% 
  ggplot(aes(x = value, y = y))+
    geom_point()+
    facet_wrap(~name, scales = 'free')

```

\subsection{Teste de correlação de pearson }
```{r}

#Pvalor
result_cor_test = sapply(numericas, function(x) round(cor.test(x,y)$p.value,5))
result_cor_test

signif_num_vars = numericas[result_cor_test < 0.05]
signif_num_vars %>% head()
  
```

## Boxplot das covariáveis categóricas em relação à variável resposta

Como o intuito é verificar mais se dentro das covariáveis alguma varíavel apresenta maior influência que as outras, os nomes dentro das variáveis ficou corrompido, por isso, caso haja necessidade de ver algum covariável com mais detalhe posso criar um gráfico só pra ela.

```{r}
cbind(categoricas[1:6],y) %>% 
  pivot_longer(-y) %>% 
  ggplot(aes(x = value, y = y))+
    geom_boxplot()+
    facet_wrap(~name, scales = 'free')

cbind(categoricas[7:13],y) %>% 
  pivot_longer(-y) %>% 
  ggplot(aes(x = value, y = y))+
    geom_boxplot()+
    facet_wrap(~name, scales = 'free')

cbind(categoricas[14:20],y) %>% 
  pivot_longer(-y) %>% 
  ggplot(aes(x = value, y = y))+
    geom_boxplot()+
    facet_wrap(~name, scales = 'free')

cbind(categoricas[21:27],y) %>% 
  pivot_longer(-y) %>% 
  ggplot(aes(x = value, y = y))+
    geom_boxplot()+
    facet_wrap(~name, scales = 'free')

cbind(categoricas[28:34],y) %>% 
  pivot_longer(-y) %>% 
  ggplot(aes(x = value, y = y))+
    geom_boxplot()+
    facet_wrap(~name, scales = 'free')

cbind(categoricas[35:39],y) %>% 
  pivot_longer(-y) %>% 
  ggplot(aes(x = value, y = y))+
    geom_boxplot()+
    facet_wrap(~name, scales = 'free')


```

### Fazendo o teste da ANOVA
```{r}
data_cat = cbind(categoricas,y) 
result_anova = summary(aov(y ~ ., data = data_cat))

```

```{r}
# pegando somente as variáveis que tiveram um pvalor abaixo de 0,05
result_anova = result_anova[[1]]
signif_cat_vars = result_anova[result_anova$`Pr(>F)` < 0.05,]

#variáveis categóricas significantes
signif_cat_vars
```


```{r}
#Pegando o nome das variáveis numéricas e categóricas
names_signif_vars_cat = signif_cat_vars %>% row.names %>% str_trim() 
names_signif_vars_cat = names_signif_vars_cat[names_signif_vars_cat!="NA"]

names_signif_vars_num = signif_num_vars %>% colnames

signif_vars = c(names_signif_vars_cat, names_signif_vars_num)

#Covariáveis significantes
signif_vars


```

Fazendo os testes de correlação e da anova, conseguiu-se reduzir o número de variáveis de 80 para 53.

Com isso, para o restante das análises serão utilizadas essas variáveis.


\subsection{Criação das variáveis dummies}


```{r, warning=F}
library(fastDummies)

n_treino = nrow(df_treino)
n_test = nrow(df_test)



df_geral = rbind(df_treino, df_test)
df_geral = df_geral[vec_util_vars]

#aplicando a técnica no dataframe de treino e teste juntos
df_geral = df_geral[signif_vars]
df_geral = dummy_cols(df_geral, select_columns = names_signif_vars_cat, 
                      remove_first_dummy = T)

treino = df_geral[1:n_treino, ]
teste = df_geral[n_treino:nrow(df_geral),]


treino = treino %>% 
  mutate(y = y) %>% 
  na.omit %>% 
  dplyr::select(!names_signif_vars_cat) 


#dimensão do dataframe de treino depois de todo o processo de avaliação e criação de variáveis
dim(treino)

model = lm(y~., data = treino)
best_model = stepAIC(model, direction = 'backward') 

best_model$coefficients %>% names
```


Transformando as variáveis categóricas em variáveis dummies aumentamos o número de variáveis do modelo de 53 para `r dim(treino)[2]` variáveis


\subsection{Seleção do modelo}

<!-- Usando a fórmula do backward usando o critério de aic chegamos nos seguintes resultados: -->
<!-- ```{r, results='hide'} -->

<!-- library(MASS) -->


<!-- model = lm(y~., data = treino) -->
<!-- best_model = stepAIC(model, direction = 'backward') -->

<!-- ``` -->

<!-- Número de variáveis selecionadas: -->
<!-- ```{r} -->
<!-- best_model$coefficients %>% names %>% length -->
<!-- ``` -->
<!-- Variáveis selecionadas: -->

<!-- ```{r} -->
<!-- best_model$coefficients %>% names -->
<!-- ``` -->

<!-- Gráfico de resíduos: -->

<!-- ```{r} -->
<!-- plot(best_model$residuals) -->
<!-- ``` -->


<!-- Preparando os dados de teste para a predição: -->
<!-- ```{r} -->
<!-- teste = teste %>% -->
<!--   dplyr::select(!names_signif_vars_cat) -->
<!-- ``` -->

<!-- Fazendo a avaliação do modelo: -->
<!-- ```{r} -->
<!-- library(forecast) -->

<!-- y_true = y -->
<!-- y_pred = predict(best_model, treino) -->

<!-- accuracy(y_true, y_pred) -->
<!-- ``` -->









# Matriz de correlação entre as variáveis quantitativas

# fazer um modelo com cada variável numérica pela variável resposta

#calcular o coeficiente de contingência

#comparação do teste da anova com cada variável categórica com a variável resposta









